{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-18T14:32:02.513675Z","iopub.execute_input":"2024-06-18T14:32:02.514117Z","iopub.status.idle":"2024-06-18T14:32:03.775234Z","shell.execute_reply.started":"2024-06-18T14:32:02.514079Z","shell.execute_reply":"2024-06-18T14:32:03.773751Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/alx-movie-recommendation-project-2024/sample_submission.csv\n/kaggle/input/alx-movie-recommendation-project-2024/movies.csv\n/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv\n/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv\n/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv\n/kaggle/input/alx-movie-recommendation-project-2024/train.csv\n/kaggle/input/alx-movie-recommendation-project-2024/test.csv\n/kaggle/input/alx-movie-recommendation-project-2024/tags.csv\n/kaggle/input/alx-movie-recommendation-project-2024/links.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Importing Our Old Hero Packages**","metadata":{}},{"cell_type":"code","source":"# Install packages here\n# Packages for data processing\nimport numpy as np\nimport pandas as pd\nimport datetime\nfrom sklearn import preprocessing\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\nfrom scipy.sparse import csr_matrix\nimport scipy as sp\n\n\n# Packages for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Packages for modeling\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise import KNNWithMeans\nfrom surprise import KNNBasic\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection import GridSearchCV\nfrom surprise import SVD\nfrom surprise import SVDpp\nfrom surprise import NMF\nfrom surprise import SlopeOne\nfrom surprise import CoClustering\nimport heapq\n\n# Packages for model evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom time import time\n\n# Package to suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Packages for saving models\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:32:09.538567Z","iopub.execute_input":"2024-06-18T14:32:09.539796Z","iopub.status.idle":"2024-06-18T14:32:11.685956Z","shell.execute_reply.started":"2024-06-18T14:32:09.539753Z","shell.execute_reply":"2024-06-18T14:32:11.684599Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Reading Our Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/train.csv')\nmovies_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/movies.csv')\nimdb_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv')\ntest_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/test.csv')\nlinks_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/links.csv')\ntags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/tags.csv')\ngenome_scores = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv')\ngenome_tags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv')\nsample_submissions = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:32:15.385581Z","iopub.execute_input":"2024-06-18T14:32:15.386213Z","iopub.status.idle":"2024-06-18T14:32:42.711339Z","shell.execute_reply.started":"2024-06-18T14:32:15.386176Z","shell.execute_reply":"2024-06-18T14:32:42.710064Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"movies_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:56:51.931630Z","iopub.execute_input":"2024-06-18T13:56:51.932066Z","iopub.status.idle":"2024-06-18T13:56:51.948999Z","shell.execute_reply.started":"2024-06-18T13:56:51.932034Z","shell.execute_reply":"2024-06-18T13:56:51.947533Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"movies_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:57:02.058890Z","iopub.execute_input":"2024-06-18T13:57:02.059328Z","iopub.status.idle":"2024-06-18T13:57:02.066876Z","shell.execute_reply.started":"2024-06-18T13:57:02.059291Z","shell.execute_reply":"2024-06-18T13:57:02.065675Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(62423, 3)"},"metadata":{}}]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:57:05.233145Z","iopub.execute_input":"2024-06-18T13:57:05.234114Z","iopub.status.idle":"2024-06-18T13:57:05.247277Z","shell.execute_reply.started":"2024-06-18T13:57:05.234072Z","shell.execute_reply":"2024-06-18T13:57:05.246011Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   userId  movieId  rating   timestamp\n0    5163    57669     4.0  1518349992\n1  106343        5     4.5  1206238739\n2  146790     5459     5.0  1076215539\n3  106362    32296     2.0  1423042565\n4    9041      366     3.0   833375837","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5163</td>\n      <td>57669</td>\n      <td>4.0</td>\n      <td>1518349992</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106343</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>1206238739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>146790</td>\n      <td>5459</td>\n      <td>5.0</td>\n      <td>1076215539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106362</td>\n      <td>32296</td>\n      <td>2.0</td>\n      <td>1423042565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9041</td>\n      <td>366</td>\n      <td>3.0</td>\n      <td>833375837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **EDA**\n\n# Outliers\n\n* Identify outliers: Outliers are data points that differ significantly from other observations. They can skew and mislead the training process of a machine learning model.\n* Detecting outliers: Use statistical methods such as Z-scores or IQR (Interquartile Range) to detect outliers.\n* Handling outliers: Decide whether to remove or transform the outliers depending on their impact on the dataset.\n# Understanding Relationships Between Various Attributes and Structure of the Data\n* Correlation Analysis: Use correlation matrices to understand the relationships between numerical attributes.\n* Visualization Techniques: Employ scatter plots, pair plots, and heatmaps to visualize and explore relationships.\n* Data Structure: Understand the structure of the data, including the distribution of values and the presence of any missing values.\n# Recognizing Important Variables\n* Feature Importance: Use techniques like Random Forests, Gradient Boosting, or SHAP values to determine feature importance.\n* Domain Knowledge: Incorporate domain expertise to identify which variables are likely to be important.\n* Statistical Tests: Conduct statistical tests to identify variables that have significant effects on the target variable.\nBy understanding the data through these steps, we ensure a robust foundation for building and evaluating machine learning models.\n\nLets Check whether or not we have any missing values in our dataset","metadata":{}},{"cell_type":"code","source":"print(\"Train: \")\nprint(str(train_df.isnull().sum()))\nprint(\"************\")\nprint(\"Test: \")\nprint(str(test_df.isnull().sum()))\nprint(\"************\")\nprint(\"Movies: \")\nprint(str(movies_df.isnull().sum()))\nprint(\"************\")\nprint(\"Links: \")\nprint(str(links_df.isnull().sum()))\nprint(\"************\")\nprint(\"IMDB: \")\nprint(str(imdb_df.isnull().sum()))\nprint(\"************\")\nprint(\"Genome scores: \")\nprint(str(genome_scores.isnull().sum()))\nprint(\"************\")\nprint(\"Genome tags: \")\nprint(str(genome_tags.isnull().sum()))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:57:09.857641Z","iopub.execute_input":"2024-06-18T13:57:09.858500Z","iopub.status.idle":"2024-06-18T13:57:09.996969Z","shell.execute_reply.started":"2024-06-18T13:57:09.858455Z","shell.execute_reply":"2024-06-18T13:57:09.995835Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train: \nuserId       0\nmovieId      0\nrating       0\ntimestamp    0\ndtype: int64\n************\nTest: \nuserId     0\nmovieId    0\ndtype: int64\n************\nMovies: \nmovieId    0\ntitle      0\ngenres     0\ndtype: int64\n************\nLinks: \nmovieId      0\nimdbId       0\ntmdbId     107\ndtype: int64\n************\nIMDB: \nmovieId              0\ntitle_cast       10068\ndirector          9874\nruntime          12089\nbudget           19372\nplot_keywords    11078\ndtype: int64\n************\nGenome scores: \nmovieId      0\ntagId        0\nrelevance    0\ndtype: int64\n************\nGenome tags: \ntagId    0\ntag      0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Merge datasets if necessary\nmerged_df = pd.merge(imdb_df, links_df, on='movieId')\n\n# Handle missing values\nmerged_df = merged_df.dropna()\n\n# Convert data types if necessary\nmerged_df['movieId'] = merged_df['movieId'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:32:58.623962Z","iopub.execute_input":"2024-06-18T14:32:58.624383Z","iopub.status.idle":"2024-06-18T14:32:58.673478Z","shell.execute_reply.started":"2024-06-18T14:32:58.624351Z","shell.execute_reply":"2024-06-18T14:32:58.671981Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Feature engeneered\n","metadata":{}},{"cell_type":"code","source":"# Merge train_df with movies_df to get movie details\nmerged_df = pd.merge(train_df, movies_df, on='movieId')\n\n# Ensure the genres column exists and is processed correctly\nif 'genres' in merged_df.columns:\n    # Create dataframe containing only the movieId and genres\n    movies_genres = pd.DataFrame(merged_df[['movieId', 'genres']], columns=['movieId', 'genres'])\n\n    # Split genres separated by \"|\" and create a list containing the genres allocated to each movie\n    movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n\n    # Create expanded dataframe where each movie-genre combination is in a separate row\n    movies_genres = pd.DataFrame([(tup.movieId, genre) for tup in movies_genres.itertuples() for genre in tup.genres],\n                                 columns=['movieId', 'genre'])\n\n    # Create a one-hot encoded dataframe for genres\n    genres_one_hot = movies_genres.pivot_table(index='movieId', columns='genre', aggfunc='size', fill_value=0)\n\n    # Merge with the original dataframe\n    merged_df = pd.merge(merged_df, genres_one_hot, on='movieId', how='inner')\nelse:\n    print(\"The 'genres' column is missing from the merged dataframe.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:33:08.315298Z","iopub.execute_input":"2024-06-18T14:33:08.315764Z","iopub.status.idle":"2024-06-18T14:34:17.939075Z","shell.execute_reply.started":"2024-06-18T14:33:08.315729Z","shell.execute_reply":"2024-06-18T14:34:17.937812Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Collaborative Filtering","metadata":{}},{"cell_type":"code","source":"# Prepare data for Surprise library\nreader = Reader(rating_scale=(0.5, 5.0))\ndata = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n\n# Build and evaluate a model using SVD\nmodel = SVD()\ncross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)\n\n# Train the model on the entire dataset\ntrainset = data.build_full_trainset()\nmodel.fit(trainset)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T14:34:41.704297Z","iopub.execute_input":"2024-06-18T14:34:41.704761Z","iopub.status.idle":"2024-06-18T15:04:52.039185Z","shell.execute_reply.started":"2024-06-18T14:34:41.704725Z","shell.execute_reply":"2024-06-18T15:04:52.037730Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Evaluating RMSE of algorithm SVD on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.8346  0.8340  0.8339  0.8334  0.8338  0.8339  0.0004  \nFit time          203.17  227.01  217.21  216.89  215.47  215.95  7.60    \nTest time         33.96   43.58   50.89   45.49   50.85   44.96   6.21    \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7b616109e4d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Recco function","metadata":{}},{"cell_type":"code","source":"def recommend_movies(user_id, num_recommendations=10):\n    # Get a list of all movie IDs\n    all_movie_ids = train_df['movieId'].unique()\n    \n    # Get the list of movies the user has already rated\n    rated_movies = train_df[train_df['userId'] == user_id]['movieId'].unique()\n    \n    # Create a list of movie IDs that the user has not rated\n    unrated_movies = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n    \n    # Predict ratings for all unrated movies\n    predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies]\n    \n    # Sort the predictions by estimated rating in descending order\n    predictions.sort(key=lambda x: x.est, reverse=True)\n    \n    # Get the top N recommendations\n    top_recommendations = predictions[:num_recommendations]\n    \n    # Return the recommended movie IDs and their estimated ratings\n    return [(pred.iid, pred.est) for pred in top_recommendations]\n\n# Example usage\nuser_id = 1  # Replace with a user ID from your dataset\nrecommendations = recommend_movies(user_id)\nprint(f\"Top recommendations for user {user_id}: {recommendations}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:05:36.109699Z","iopub.execute_input":"2024-06-18T15:05:36.110318Z","iopub.status.idle":"2024-06-18T15:05:37.079938Z","shell.execute_reply.started":"2024-06-18T15:05:36.110270Z","shell.execute_reply":"2024-06-18T15:05:37.078484Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Top recommendations for user 1: [(171495, 4.536297628683461), (7926, 4.528681941163437), (89759, 4.526350578668971), (2019, 4.523988926093174), (6669, 4.5191921995891455), (171011, 4.510305709692851), (1201, 4.487020128994383), (170705, 4.484785113013309), (4878, 4.483844391929086), (157373, 4.476746766154687)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generating predictions and Submission\n","metadata":{}},{"cell_type":"code","source":"# Prepare the test data\ntestset_for_prediction = test_df[['userId', 'movieId']].copy()\ntestset_for_prediction['rating'] = 0  # Dummy rating column to match the input format\n\n# Convert the test set to a list of tuples\ntestset_for_prediction = list(testset_for_prediction.itertuples(index=False, name=None))\n\n# Generate predictions\npredictions = model.test(testset_for_prediction)\n\n# Prepare the submission dataframe\nsubmission = pd.DataFrame([(pred.uid, pred.iid, pred.est) for pred in predictions], columns=['userId', 'movieId', 'rating'])\n\n# Create the 'Id' column by concatenating 'userId' and 'movieId'\nsubmission['Id'] = submission['userId'].astype(str) + '_' + submission['movieId'].astype(str)\n\n# Select only the 'Id' and 'rating' columns for the submission\nsubmission = submission[['Id', 'rating']]\n\n# Save the submission to a CSV file\nsubmission.to_csv('my_submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T15:06:22.074279Z","iopub.execute_input":"2024-06-18T15:06:22.075427Z","iopub.status.idle":"2024-06-18T15:08:23.611416Z","shell.execute_reply.started":"2024-06-18T15:06:22.075383Z","shell.execute_reply":"2024-06-18T15:08:23.609903Z"},"trusted":true},"execution_count":9,"outputs":[]}]}
